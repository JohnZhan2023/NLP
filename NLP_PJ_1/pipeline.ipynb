{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhanjh/miniconda3/envs/nlp/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/zhanjh/miniconda3/envs/nlp/lib/python3.9/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/home/zhanjh/miniconda3/envs/nlp/lib/python3.9/site-packages/torchtext/data/example.py:94: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
      "/home/zhanjh/miniconda3/envs/nlp/lib/python3.9/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
      "/home/zhanjh/miniconda3/envs/nlp/lib/python3.9/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import torchtext\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "TEXT = torchtext.data.Field(lower=True,fix_length=200,batch_first=True)\n",
    "LABEL = torchtext.data.Field(sequential=False)\n",
    "train,valid,test = torchtext.datasets.SST.splits(TEXT,LABEL, fine_grained=True)\n",
    "# TEXT and LABEL are objects adapted for the our data(we assume the train set is big enough to include almost all words)\n",
    "TEXT.build_vocab(train,vectors=GloVe(name='6B',dim=100),max_size=20000,min_freq=10)\n",
    "LABEL.build_vocab(train)\n",
    "\n",
    "train_iter, valid_iter, test_iter = torchtext.data.BucketIterator.splits((train,valid,test),batch_size=16)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 200])\n",
      "torch.Size([16])\n",
      "tensor([2, 3, 3, 1, 1, 1, 2, 2, 2, 3, 4, 1, 1, 1, 3, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhanjh/miniconda3/envs/nlp/lib/python3.9/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iter:\n",
    "    print(batch.text.size())\n",
    "    print(batch.label.size())\n",
    "    print(batch.label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1682, 100])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.vectors.size()\n",
    "# here TEXT acts as a translator between words and their indices, and also provides the pretrained word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The detailed model design is too complex and it is written in the corresponding py file\n",
    "\n",
    "I decompose the whole model into 2 parts: encoder and backbone.\n",
    "\n",
    "I wrap both of the two parts with a classifier and define a class of trainer for grid search.\n",
    "\n",
    "Based on my previous experience, I choose Adam and upgrade the rnn to lstm. Additionally, I set the dropout to 0.1 to avoid overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.backends\n",
    "from classifier import classifier\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from trainer import Trainer\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enabled = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXP1: glove VS random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhanjh/miniconda3/envs/nlp/lib/python3.9/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/21 [00:00<?, ?it/s]/home/zhanjh/miniconda3/envs/nlp/lib/python3.9/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "  5%|▍         | 1/21 [00:13<04:31, 13.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 1.7285, Validation Loss: 1.7336, Validation Acc: 0.2534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 10/21 [02:11<02:24, 13.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Training Loss: 1.5990, Validation Loss: 1.6627, Validation Acc: 0.3678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 11/21 [02:25<02:14, 13.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.3624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 20/21 [04:22<00:13, 13.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Training Loss: 1.5217, Validation Loss: 1.6608, Validation Acc: 0.3833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [04:36<00:00, 13.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.3670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_size = 100\n",
    "hidden_size = 512\n",
    "output_size = 6 # due to the fine_grained=True, the tag is from 1-5, so the output_size is 6\n",
    "dropout = 0.1\n",
    "encoder = \"rnn\"\n",
    "embedding_type = \"glove\"\n",
    "attention = False\n",
    "num_layers = 2\n",
    "\n",
    "lr=0.0002\n",
    "bsz=16\n",
    "epochs=21\n",
    "train_iter, valid_iter, test_iter = torchtext.data.BucketIterator.splits((train,valid,test),batch_size=bsz)\n",
    "model = classifier(input_size,hidden_size,num_class=output_size,encoder=encoder,embedding_type=embedding_type,attention=attention,TEXT=TEXT)\n",
    "model = classifier(input_size,hidden_size,dropout=dropout,num_layers=num_layers, num_class=output_size,encoder=encoder,embedding_type=embedding_type,attention=attention,TEXT=TEXT)\n",
    "trainer = Trainer(model, TEXT, LABEL, batch_size=bsz, lr=lr, epochs=epochs)\n",
    "trainer.train(train_iter, valid_iter, test_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 1/21 [00:13<04:28, 13.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 1.7284, Validation Loss: 1.7337, Validation Acc: 0.2534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 10/21 [02:11<02:25, 13.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Training Loss: 1.6753, Validation Loss: 1.7020, Validation Acc: 0.3224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 11/21 [02:26<02:15, 13.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.3321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 20/21 [04:26<00:13, 13.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Training Loss: 1.6116, Validation Loss: 1.6898, Validation Acc: 0.3342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [04:40<00:00, 13.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.3511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_size = 100\n",
    "hidden_size = 512\n",
    "output_size = 6\n",
    "dropout = 0.1\n",
    "encoder = \"rnn\"\n",
    "embedding_type = \"trainable\"\n",
    "attention = False\n",
    "num_layers = 2\n",
    "\n",
    "lr=0.0002\n",
    "bsz=16\n",
    "epochs=21\n",
    "train_iter, valid_iter, test_iter = torchtext.data.BucketIterator.splits((train,valid,test),batch_size=bsz)\n",
    "model = classifier(input_size,hidden_size,num_class=output_size,encoder=encoder,embedding_type=embedding_type,attention=attention,TEXT=TEXT)\n",
    "model = classifier(input_size,hidden_size,dropout=dropout,num_layers=num_layers, num_class=output_size,encoder=encoder,embedding_type=embedding_type,attention=attention,TEXT=TEXT)\n",
    "trainer = Trainer(model, TEXT, LABEL, batch_size=bsz, lr=lr, epochs=epochs)\n",
    "trainer.train(train_iter, valid_iter, test_iter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result shows that the pretrained glove is better. So we will continue to use it later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXP2: RNN(lstm) VS transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 1/21 [00:04<01:28,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 1.7272, Validation Loss: 1.7350, Validation Acc: 0.2534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 11/21 [00:47<00:43,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Training Loss: 1.7078, Validation Loss: 1.7377, Validation Acc: 0.2770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [01:30<00:00,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Training Loss: 1.6745, Validation Loss: 1.6967, Validation Acc: 0.3261\n",
      "Test Accuracy: 0.3127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_size = 100\n",
    "hidden_size = 512\n",
    "output_size = 6\n",
    "dropout = 0.1\n",
    "encoder = \"transformer\"\n",
    "embedding_type = \"glove\"\n",
    "attention = False\n",
    "num_layers = 2\n",
    "\n",
    "lr=0.0002\n",
    "bsz=16\n",
    "epochs=21\n",
    "train_iter, valid_iter, test_iter = torchtext.data.BucketIterator.splits((train,valid,test),batch_size=bsz)\n",
    "model = classifier(input_size,hidden_size,num_class=output_size,encoder=encoder,embedding_type=embedding_type,attention=attention,TEXT=TEXT)\n",
    "model = classifier(input_size,hidden_size,dropout=dropout,num_layers=num_layers, num_class=output_size,encoder=encoder,embedding_type=embedding_type,attention=attention,TEXT=TEXT)\n",
    "trainer = Trainer(model, TEXT, LABEL, batch_size=bsz, lr=lr, epochs=epochs)\n",
    "trainer.train(train_iter, valid_iter, test_iter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can directly feel that the transformer is faster!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it lags behind the rnn. Maybe, two layers restrict transformer's expression ability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXP3: attention layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 1/21 [00:04<01:34,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 1.7278, Validation Loss: 1.7323, Validation Acc: 0.2534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 10/21 [00:46<00:50,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Training Loss: 1.6918, Validation Loss: 1.6978, Validation Acc: 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 11/21 [00:51<00:47,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.3299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 20/21 [01:32<00:04,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Training Loss: 1.6601, Validation Loss: 1.6746, Validation Acc: 0.3560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [01:37<00:00,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.3403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_size = 100\n",
    "hidden_size = 512\n",
    "output_size = 6\n",
    "dropout = 0.1\n",
    "encoder = \"transformer\"\n",
    "embedding_type = \"glove\"\n",
    "attention = True\n",
    "num_layers = 2\n",
    "\n",
    "lr=0.0002\n",
    "bsz=16\n",
    "epochs=21\n",
    "train_iter, valid_iter, test_iter = torchtext.data.BucketIterator.splits((train,valid,test),batch_size=bsz)\n",
    "model = classifier(input_size,hidden_size,num_class=output_size,encoder=encoder,embedding_type=embedding_type,attention=attention,TEXT=TEXT)\n",
    "model = classifier(input_size,hidden_size,dropout=dropout,num_layers=num_layers, num_class=output_size,encoder=encoder,embedding_type=embedding_type,attention=attention,TEXT=TEXT)\n",
    "trainer = Trainer(model, TEXT, LABEL, batch_size=bsz, lr=lr, epochs=epochs)\n",
    "trainer.train(train_iter, valid_iter, test_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 1/21 [00:14<04:54, 14.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 1.7297, Validation Loss: 1.7313, Validation Acc: 0.2534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 10/21 [02:22<02:35, 14.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Training Loss: 1.5414, Validation Loss: 1.6432, Validation Acc: 0.3942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 11/21 [02:37<02:25, 14.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.3593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 20/21 [04:46<00:14, 14.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Training Loss: 1.4755, Validation Loss: 1.6498, Validation Acc: 0.3851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [05:01<00:00, 14.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.3584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_size = 100\n",
    "hidden_size = 512\n",
    "output_size = 6\n",
    "dropout = 0.1\n",
    "encoder = \"rnn\"\n",
    "embedding_type = \"glove\"\n",
    "attention = True\n",
    "num_layers = 2\n",
    "\n",
    "lr=0.0002\n",
    "bsz=16\n",
    "epochs=21\n",
    "train_iter, valid_iter, test_iter = torchtext.data.BucketIterator.splits((train,valid,test),batch_size=bsz)\n",
    "model = classifier(input_size,hidden_size,num_class=output_size,encoder=encoder,embedding_type=embedding_type,attention=attention,TEXT=TEXT)\n",
    "model = classifier(input_size,hidden_size,dropout=dropout,num_layers=num_layers, num_class=output_size,encoder=encoder,embedding_type=embedding_type,attention=attention,TEXT=TEXT)\n",
    "trainer = Trainer(model, TEXT, LABEL, batch_size=bsz, lr=lr, epochs=epochs)\n",
    "trainer.train(train_iter, valid_iter, test_iter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lr and batchsize has been searched in the py file trainer.py. \n",
    "\n",
    "Due to its complexity, I don't show it here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sota"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous exps aim to indicate the hyperparameters' influence on the models. For better performance and application, I adapt gru to substitute for the lstm for fast speed and do the data augmentation.\n",
    "\n",
    "For the data augmentation, I shorten the fix_length to 50 as I find that the max length of the sentence is 32 so we can reduce the padding info.\n",
    "\n",
    "Additionally, I adapt large pretrained embedding to bring my model to the next level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:04<01:18,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 1.5782, Validation Loss: 1.5797, Validation Acc: 0.2625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:15<01:03,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Training Loss: 1.4205, Validation Loss: 1.4913, Validation Acc: 0.3960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:20<01:01,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.4023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:32<00:48,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Training Loss: 1.4085, Validation Loss: 1.5019, Validation Acc: 0.3860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:36<00:45,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.3810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [00:48<00:32,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Training Loss: 1.3592, Validation Loss: 1.5082, Validation Acc: 0.3806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [00:52<00:28,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.3869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [01:04<00:16,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Training Loss: 1.3010, Validation Loss: 1.5079, Validation Acc: 0.3869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [01:09<00:12,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.4163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:21<00:00,  4.06s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch.backends\n",
    "from classifier import classifier\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from trainer import Trainer\n",
    "import torchtext\n",
    "from torchtext.vocab import GloVe\n",
    "# set the random seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "TEXT = torchtext.data.Field(lower=True,fix_length=50,batch_first=True)\n",
    "LABEL = torchtext.data.Field(sequential=False)\n",
    "train,valid,test = torchtext.datasets.SST.splits(TEXT,LABEL, fine_grained=True)\n",
    "# TEXT and LABEL are objects adapted for the our data(we assume the train set is big enough to include almost all words)\n",
    "TEXT.build_vocab(train,vectors=GloVe(name='6B',dim=300),max_size=20000,min_freq=10)\n",
    "LABEL.build_vocab(train)\n",
    "\n",
    "#train_iter, valid_iter, test_iter = torchtext.data.BucketIterator.splits((train,valid,test),batch_size=16)\n",
    "\n",
    "input_size = 300\n",
    "hidden_size = 512\n",
    "output_size = 5\n",
    "dropout = 0.1\n",
    "encoder = \"gru\"\n",
    "embedding_type = \"glove\"\n",
    "attention = True\n",
    "num_layers = 2\n",
    "\n",
    "lr=0.0001\n",
    "bsz=16\n",
    "epochs=20\n",
    "train_iter, valid_iter, test_iter = torchtext.data.BucketIterator.splits((train,valid,test),batch_size=bsz)\n",
    "model = classifier(input_size,hidden_size,num_class=output_size,encoder=encoder,embedding_type=embedding_type,attention=attention,TEXT=TEXT)\n",
    "model = classifier(input_size,hidden_size,dropout=dropout,num_layers=num_layers, num_class=output_size,encoder=encoder,embedding_type=embedding_type,attention=attention,TEXT=TEXT)\n",
    "trainer = Trainer(model, TEXT, LABEL, batch_size=bsz, lr=lr, epochs=epochs)\n",
    "trainer.train(train_iter, valid_iter, test_iter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result\n",
    "The best setting for such a task is rnn(gru) with glove pretrained embedding, no attention.\n",
    "\n",
    "It reaches 41.63% in test."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
